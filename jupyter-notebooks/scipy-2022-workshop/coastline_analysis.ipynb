{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coastline Recession in Bangladesh: A Temporal Analysis\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/planetlabs/notebooks/blob/scipy-2022/jupyter-notebooks/scipy-2022-workshop/coastline_analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook tutorial, we will be analyzing a pretty severe example of coastal erosion. To do so we will:\n",
    "- Extract data from multi-band imagery\n",
    "- Compute the normalized difference water index (NDWI)\n",
    "- Use NDWI to identify which pixels are associated to water and which pixels are associated with land\n",
    "- Analyze coastal erosion within the area of interest (AOI), using classical image processing and computer vision techniques\n",
    "\n",
    "We have provided you with data for your AOI, which has already been mosaiced, processed, and downloaded.\n",
    "\n",
    "This AOI and analysis has been inspired by a recent paper: Crawford, T.W. et al., Coastal Erosion and Human Perceptions of Revetment Protection in the Lower Meghna Estuary of Bangladesh. Remote Sens. 2020, 12, 3108. https://doi.org/10.3390/rs12183108\n",
    "\n",
    "**For this tutorial, you will need to:**\n",
    "- Download all of the data needed for this analysis. If you're running this in Colab, then the data will already be downloaded. Otherwise, please download these data in advance of the tutorial, as this may take some time: \n",
    "https://github.com/planetlabs/notebooks/blob/scipy-2022/jupyter-notebooks/scipy-2022-workshop/0_download_data.ipynb\n",
    "- Install and import the packages below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -O tmp.zip https://hello.planet.com/data/s/Y2wFKNFNTwHxot8/download/scipy2022_workshop_data.zip && unzip tmp.zip && rm tmp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve data\n",
    "Within our data folder, labelled `scipy2022_workshop_data`, we have both analytic images and visual images. While these images reflect the same AOI, they are used for different purposes. The visual images are colour-corrected and intended to be viewed and analyzed by the human eye, while the analytical images are unorthorectified, radiometrically-calibrated, and are stored as 16-bit scaled radiance, which are intended to be used for scientific purposes.\n",
    "\n",
    "Let's retrieve both the multi-band and visual-band images across our entire time of interest (2017 - 2022), then sort the data to be chronological.\n",
    "\n",
    "The AOI encapsulates a small, 7 km (4.4 mi) long, coastal region in Kamalnagar, Chittagong, Bangladesh, which is located in Southern Bangladesh, where the ocean (Bay of Bengal) meets a major inlet, the Meghna River. We have chosen to image the AOI once each spring to analyze.\n",
    "\n",
    "<img src=\"assets/region.png\" height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the analytic and visual data! \n",
    "\n",
    "We note that this method below only works for Linux and Unix (i.e., MacOS) operating systems, however is you're running this on Colab, this will work just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this directory as needed to reflect your local files\n",
    "data_directory = \"scipy2022_workshop_data\"\n",
    "\n",
    "# Find all relevant files\n",
    "analytic_filenames = glob(data_directory + \"/*analytic/composite.tif\")\n",
    "visual_filenames = glob(data_directory + \"/*visual/composite.tif\")\n",
    "\n",
    "# Sort the file chronologically, from 2017 to 2022\n",
    "analytic_filenames.sort()\n",
    "visual_filenames.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to create an image processing pipeline! For simplicity, we will wrap each method into individual functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract spectral bands\n",
    "Create a function to extract spectral bands from a PlanetScope 4-band imagery.\n",
    "These spectral bands will be used later to compute the normalized difference water index (NDWI), which will be used to find which pixels are associated to water and which are associated to land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_bands(image_filename):\n",
    "    \"\"\"\n",
    "    Extracts green and NIR band data from a PlanetScope 4-band image.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        image_filename : str\n",
    "                     The input path to a PlanetScope 4-Band image.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        band_green : Array[int]\n",
    "                     Green band image.\n",
    "        band_nir :   Array[int]\n",
    "                     NIR band image.\n",
    "    \"\"\"\n",
    "    with rasterio.open(image_filename) as src:\n",
    "        band_green = src.read(2)\n",
    "\n",
    "    with rasterio.open(image_filename) as src:\n",
    "        band_nir = src.read(4)\n",
    "\n",
    "    return band_green, band_nir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how this function works for second data point in our time series, in 2018. Since we've sorted our analytic and visual filenames, the 2018 image will be the second image (n = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's take our 2018 data as an example (year number 2 in our dataset)\n",
    "n = 1\n",
    "# Extract the green and NIR bands from 2018's 4-band analytic image\n",
    "band_green, band_nir = extract_spectral_bands(analytic_filenames[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the green band using a non-default colour map & a colour bar\n",
    "# see also: https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "fig = plt.imshow(band_green)\n",
    "fig.set_cmap('gist_earth')\n",
    "plt.colorbar()\n",
    "plt.title(\"Green Band\")\n",
    "\n",
    "# Display the results.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the red band\n",
    "fig = plt.imshow(band_nir)\n",
    "fig.set_cmap('inferno')\n",
    "plt.colorbar()\n",
    "plt.title(\"NIR Band\")\n",
    "\n",
    "# Since the axis labels are useless here, let's turn them off.\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the results.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose scene using visual imagery\n",
    "Create a function to compose a scene, given red, green, and blue bands from visual band PlanetScope 4-band imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_scene(image_filename):\n",
    "    \"\"\"\n",
    "    Extracts red, green, and blue bands from a PlanetScope 4-band image and\n",
    "    stacks them to compose a scene.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        image_filename : str\n",
    "                     The input path to a PlanetScope 4-Band image.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        band_red :   Array[int]\n",
    "                     Red band image.\n",
    "        band_green : Array[int]\n",
    "                     Green band image.\n",
    "        band_blue :  Array[int]\n",
    "                     Blue band image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract visual imagery\n",
    "    with rasterio.open(image_filename) as src:\n",
    "        band_red = src.read(1)\n",
    "    with rasterio.open(image_filename) as src:\n",
    "        band_green = src.read(2)\n",
    "    with rasterio.open(image_filename) as src:\n",
    "        band_blue = src.read(3)\n",
    "\n",
    "    # Stack the 3 bands to create an RGB visual image\n",
    "    visual_image = np.dstack((band_red, band_green, band_blue))\n",
    "\n",
    "    return visual_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the AOI looks like in visual band imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract visual images\n",
    "visual_image = compose_scene(visual_filenames[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(visual_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"2018 visual image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Normalized Difference Water Index (NDWI)\n",
    "This function will measure the\n",
    "[normalized difference water index](https://en.wikipedia.org/wiki/Normalized_difference_water_index) (NDWI), \n",
    "defined as: $NDWI = (green - NIR) / (green + NIR)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_ndwi(band_green, band_nir):\n",
    "    \"\"\"\n",
    "    Measures the normalized difference water index (NDWI).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        band_green : Array[int]\n",
    "               Normalized green band image.\n",
    "        band_nir : Array[int]\n",
    "               Normalized NIR band image.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        ndwi : Array[float]\n",
    "               Normalized difference water index    \n",
    "    \"\"\"\n",
    "\n",
    "    # Allow division by zero\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "    # Calculate NDWI\n",
    "    ndwi = (band_green.astype(float) - band_nir.astype(float)) / (band_green +\n",
    "                                                                  band_nir)\n",
    "\n",
    "    return ndwi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now. let's use our analytic imagery to compute the NDWI, which helps us determine which pixels are associated to water and which are associated to land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute NDWI\n",
    "ndwi = measure_ndwi(band_green, band_nir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ndwi)\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.title(\"2018 NDWI Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the strip of coastline on the right side of the AOI has relatively low NDWI values and the water on the left has relatively high NDWI values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find water and land pixels\n",
    "NDWI values range from -1 to +1. Pixels which have a relatively high NDWI value (NDWI >= 0.3) are likely to be\n",
    "associated with water, whereas pixels with values under this threshold \n",
    "(NDWI < 0.3) are unlikely to be associated with water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_water_and_land(ndwi):\n",
    "    \"\"\"\n",
    "    Given an NDWI image, associate an image's pixels with either water or land.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        ndwi : Array[float]\n",
    "               Normalized difference water index\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        water_mask : Array[int]\n",
    "               A binary mask for water\n",
    "        land_mask :  Array[int]\n",
    "               A binary mask for land\n",
    "    \"\"\"\n",
    "\n",
    "    # Although the water threshold is NDWI >= 0.3\n",
    "    # we'll set it lower to account of murky waters\n",
    "    WATER_THRESHOLD = 0.0\n",
    "\n",
    "    # Create arrays of NANs\n",
    "    water_mask = np.full(ndwi.shape, np.nan)\n",
    "    land_mask = np.full(ndwi.shape, np.nan)\n",
    "\n",
    "    # Threshold the NDWI image and create water & land masks\n",
    "    water_mask[ndwi >= WATER_THRESHOLD] = 1\n",
    "    land_mask[ndwi < WATER_THRESHOLD] = 1\n",
    "\n",
    "    return water_mask, land_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the masks we created. Our `find_water_and_land` function gives us two arrays - both with 0s and 1s, indicating where we can find water, indicated as a 1, and where we can find land, indicated as a 0. Let's take a moment to visualize our land mask as a `numpy` array. Note: NANs represent regions of the maps that have been clipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create water and land masks from the NDWI array\n",
    "water_mask, land_mask = find_water_and_land(ndwi)\n",
    "print(land_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize these water/land mask arrays as maps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.imshow(water_mask)\n",
    "plt.axis('off')\n",
    "plt.title(\"2018 water mask\")\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(land_mask)\n",
    "plt.axis('off')\n",
    "plt.title(\"2018 land mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These masks align quite closely with where water and land reside, however notice how we see holes in the water and land masks? In the water mask, it is likely due to the fact that we are imaging especially murky water with either excessive vegetation growth, or perhaps these pixels are associated with sandbars off of the coast! For the land mask, we are likely picking up small bodies of water inland.\n",
    "\n",
    "For our coastline analysis, it would be most helpful for us to have clean distinctions between what is \"mostly land\" to what is \"mostly water\". We can do this by applying filters to clean-up our pixel classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Filters\n",
    "We can apply [morphological filters](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html)\n",
    "to filter out the unwanted pixels in the water and land masks.\n",
    "We use a closing filter will close small clusters of pixels (e.g., holes) inside parts of a mask.\n",
    "Following, we use an opening filter will remove any small clusters of pixels outside a mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mask(closing_kernel_size, opening_kernel_size, mask):\n",
    "    \"\"\"\n",
    "    Given a mask, apply morphological filters (closing followed by opening) \n",
    "    to filter out unwanted pixels.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "       closing_kernel_size : Int\n",
    "                             Size of the closing kernel in pixels\n",
    "       opening_kernel_size : Int\n",
    "                             Size of the opening kernel in pixels\n",
    "        mask : Array[int]\n",
    "               A binary mask\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        mask_closed_opened : Array[int]\n",
    "               A morphologically filtered binary mask\n",
    "    \"\"\"\n",
    "\n",
    "    ## Closing filter: Remove empty pixels within mask\n",
    "    # Create a kernel which is closing_kernel_size^2 in size\n",
    "    closing_kernel_element = (closing_kernel_size, closing_kernel_size)\n",
    "    # Initialize a closing filter kernel\n",
    "    closing_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,\n",
    "                                               closing_kernel_element)\n",
    "    # Apply closing filter to mask\n",
    "    mask_closed = cv2.morphologyEx(np.nan_to_num(mask), cv2.MORPH_CLOSE,\n",
    "                                   closing_kernel)\n",
    "\n",
    "    ## Opening filter: Removing filled pixels outside of mask\n",
    "    # Create a kernel which is closing_kernel_size^2 in size\n",
    "    opening_kernel_element = (opening_kernel_size, opening_kernel_size)\n",
    "    # Initialize an opening filter kernel\n",
    "    opening_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,\n",
    "                                               opening_kernel_element)\n",
    "    # Apply opening filter to closed mask\n",
    "    mask_closed_opened = cv2.morphologyEx(mask_closed, cv2.MORPH_OPEN,\n",
    "                                          opening_kernel)\n",
    "\n",
    "    # Ensure the clipped areas remain clipped\n",
    "    mask_closed_opened[mask_closed_opened == 0] = np.nan\n",
    "\n",
    "    return mask_closed_opened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this how this works in practice. Let's apply these morphological filters to both the water and land masks. These kernel sizes were chosen by empirical observations. To put them in physical units, multiply them by the pixel size (~3.7m)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the water mask\n",
    "closing_kernel_size = 29\n",
    "opening_kernel_size = 13\n",
    "water_mask_filtered = filter_mask(closing_kernel_size, opening_kernel_size,\n",
    "                                  water_mask)\n",
    "\n",
    "# Filter the land mask\n",
    "closing_kernel_size = 3\n",
    "opening_kernel_size = 101\n",
    "land_mask_filtered = filter_mask(closing_kernel_size, opening_kernel_size,\n",
    "                                 land_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.imshow(water_mask_filtered)\n",
    "plt.axis('off')\n",
    "plt.title(\"2018 filtered water mask\")\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(land_mask_filtered)\n",
    "plt.axis('off')\n",
    "plt.title(\"2018 filtered land mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viola! Now we have clear distinctions between land and water without any pesky pixels to distract us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can implement this entire process we just walked through, to each of the images over the time series, from 2017 to 2022.\n",
    "\n",
    "Below we've set up a for loop, which will loop through each of the functions we created above, which will extract processed water and land masks for each date in our time series, from 2017 to 2022. At the end of our loop, we store the filtered land mask in a list for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of years in the time series\n",
    "NUM_YEARS = 2022 - 2017\n",
    "# Create an empty list to append data to\n",
    "all_land_masks = []\n",
    "\n",
    "# Loop through each year\n",
    "for n in range(NUM_YEARS + 1):\n",
    "    # Extract green, red, and NIR data from 4-Band imagery\n",
    "    band_green, band_nir = extract_spectral_bands(analytic_filenames[n])\n",
    "    # Extract visual images\n",
    "    visual_image = compose_scene(visual_filenames[n])\n",
    "    # Compute NDWI\n",
    "    ndwi = measure_ndwi(band_green, band_nir)\n",
    "    # Mask regions with water\n",
    "    water_mask, land_mask = find_water_and_land(ndwi)\n",
    "    # Filter masks to fill out space\n",
    "    water_mask_filtered = filter_mask(29, 13, water_mask)\n",
    "    land_mask_filtered = filter_mask(3, 101, land_mask)\n",
    "    # Add land mask to a list for further analysis\n",
    "    all_land_masks.append(land_mask_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our NDWI thresholds and land/water masks for each date in our time series, we can start interpreting the year-over-year changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at landmass loss by calculating the physical area of land lost over time. Each pixel in our 4-band data is about 3.7 meters wide and has an area of 3.7 x 3.7 = 13.69 meters squared. For more information, check out our [Dev Center](https://developers.planet.com/docs/data/planetscope/)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landmass Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The difference between the 2017 and the 2022 land masks\n",
    "# Using nan_to_num function to set all NANs to zero, as to not blow up the code\n",
    "land_difference = np.nan_to_num(all_land_masks[0]) - np.nan_to_num(\n",
    "    all_land_masks[-1])\n",
    "\n",
    "# resolution in m\n",
    "resolution = 3.7\n",
    "# area per pixel in m^2\n",
    "area_per_pixel = resolution**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Total landmass lost: {round(np.nansum(land_difference) * area_per_pixel * 1e-6)} milion m^2 over the past {NUM_YEARS} years\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the total landmass lost over our time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Landmass Lost\n",
    "plt.figure(4)\n",
    "plt.imshow(land_difference)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title(\"Cumulative landmass lost from 2017 to 2022\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute and visualize the amount of land lost over the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A time array for the time series\n",
    "time = np.array(range(len(all_land_masks)))\n",
    "\n",
    "# Compute the difference between the landmass of 2017 to each year\n",
    "landmass_loss = np.nansum(all_land_masks[0]) - list(\n",
    "    map(np.nansum, all_land_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Landmass Lost\n",
    "plt.figure(5)\n",
    "plt.plot(time, landmass_loss * 1e-3, 'o-')\n",
    "plt.title(\"Total Landmass lost over 5 years\")\n",
    "plt.xlabel(\"Years since 2017\")\n",
    "plt.ylabel(r\"Area lost (1000 m$^2$)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The landmass lost over the past 5 years in increasing rather quickly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how quickly is the coastal region losing land? Let's compute the velocity of landmass lost by measuring the change of land mass over the change of time, i.e., $v(t) = \\Delta M / \\Delta t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the velocity of landmass lost\n",
    "landmass_loss_velocity = np.diff(landmass_loss) / np.diff(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velocity of Landmass Lost\n",
    "plt.figure(6)\n",
    "plt.plot(time[1:], landmass_loss_velocity * 1e-3, 'o-')\n",
    "plt.title(\"Landmass lost over 5 years is speeding up\")\n",
    "plt.xlabel(\"Years since 2017\")\n",
    "plt.ylabel(r\"Speed of area lost per year (1000 m$^2$ / yr)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The landmass lost doesn't appear to be happening at a constant rate - it appears to be speeding up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out how quickly the speed of landmass lost is speeding up by measuring its acceleration, i.e., $a(t) = \\Delta v / \\Delta t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the acceleration of landmass lost\n",
    "landmass_loss_acceleration = np.diff(landmass_loss_velocity) / np.diff(\n",
    "    time[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that our landmass loss over the past 5 years is accelerating\n",
    "plt.figure(7)\n",
    "plt.plot(time[2:], landmass_loss_acceleration * 1e-3, 'o-')\n",
    "plt.title(\"Rate of landmass lost over 5 years is accelerating\")\n",
    "plt.xlabel(\"Years since 2017\")\n",
    "plt.ylabel(r\"Acceleration of area lost per year (1000 m$^2$ / yr$^2$)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speed at which this area is losing landmass is consistently accelerating!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land Recession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going one step further, we can measure coastline erosion through land recession, in other words, we can measure how much the coastline has receded inland. One way to do this is to find the coastline in 2017 and 2022, then measuring the distance between the two coasts. We can do this is by looking at the `land_difference` array and using edge detection to find the coastlines in 2017 and in 2022.\n",
    "\n",
    "Specifically, we'll employ a computer vision algorithm called \"Canny Edge Detection\" to detect the edge of the landmass at the beginning and end of our time series to that at the end of our time series. \n",
    "\n",
    "You can learn more about edge detection method we are using here: https://learnopencv.com/edge-detection-using-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the edges of the cumulative land loss map\n",
    "edges_all = cv2.Canny(image=np.uint8(land_difference),\n",
    "                      threshold1=0,\n",
    "                      threshold2=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below plot shows the relative x-axis edge values for our coastline in 2017 and in 2022, for comparison. The histogram overlayed on top shows where the edge of the coastline is most likely to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(8)\n",
    "plt.imshow(edges_all, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.title(\"Canny Edge Detection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to create an automated search for the 2017 coastline (on the left) and the 2022 coastline (on the right). We'll do this by creating a histogram of all of the coastal pixels, by binning up all of the pixels, vertically. Then, we'll find the peaks of the histogram, which will tell us where the coastlines roughly are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin up all edge pixels, vertically\n",
    "_, xpos = np.where(edges_all > 0)\n",
    "NUM_BINS = 12\n",
    "N, x = np.histogram(xpos, bins=NUM_BINS)\n",
    "bin_width = x[1] - x[0]\n",
    "\n",
    "# Find the peaks of the histogram -> these are the coastline edges\n",
    "coastlines = x[find_peaks(N)[0]]\n",
    "coastline_2017 = coastlines[0]\n",
    "coastline_2022 = coastlines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(9)\n",
    "plt.hist(xpos, bins=NUM_BINS, alpha=0.5)\n",
    "plt.axvline(x=coastline_2017 + bin_width / 2, color='k', ls='--')\n",
    "plt.axvline(x=coastline_2022 + bin_width / 2, color='k', ls='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's overlay this histogram on top of the edge detection map to ensure our detected coastlines make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(10)\n",
    "plt.imshow(edges_all, vmin=0, vmax=1)\n",
    "plt.hist(xpos, bins=NUM_BINS, alpha=0.5)\n",
    "plt.axvline(x=coastline_2017 + bin_width / 2, color='k', ls='--')\n",
    "plt.axvline(x=coastline_2022 + bin_width / 2, color='k', ls='--')\n",
    "plt.title(\"Canny Edge Detection (used for coast line detection)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It work! We have a rough estimate as to where our 2017 and 2022 coasts reside.\n",
    "\n",
    "However, we should note that this only works if the coasts are vertically aligned to the frame of reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, lets compute how much the coast has receded inland by taking the difference between the two coastline positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recession = (coastline_2022 - coastline_2017) * resolution\n",
    "\n",
    "print(f\"Land has receded {round(recession)} meters in {NUM_YEARS} years\")\n",
    "print(\n",
    "    f\"Land has receded {round(recession / NUM_YEARS)} meters/yr over the past {NUM_YEARS} years\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've made it to the end of this tutorial! \n",
    "\n",
    "We hope you now have a better understanding of how to use geospatial/raster image processing and computer vision tools to analyze coastal erosion.\n",
    "\n",
    "If you have any additional questions, please don't hesitate to reach out to us using the email addresses below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kevin Lacaille: kevin.lacaille@planet.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mansi Shah: mansi@planet.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develepr Relations @ Planet: developers@planet.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "169c2a6d6f6b3b6f3764016389a0a1d9dfa7d18d4ccd8b215971315354c20651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
