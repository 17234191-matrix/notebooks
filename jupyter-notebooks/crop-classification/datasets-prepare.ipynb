{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Datasets\n",
    "\n",
    "Once the datasets are obtained, they must be aligned and cropped to the same region. In this notebook, we crop the Planet scene and ground truth data to the aoi.\n",
    "\n",
    "The sections are:\n",
    "- Crop Ground Truth Data to AOI\n",
    "- Crop Image to AOI\n",
    "- Visualize Ground Truth Data over Image\n",
    "\n",
    "Note: there are quite a few cells that are dedicated to defining utility functions that have broad applicability and can be lifted from this notebook. They are indicated by a line at the top of the cell that starts with\n",
    "\n",
    "```\n",
    "# Utility functions:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "import ipyleaflet as ipyl\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from planet import Auth, Session\n",
    "from shapely.geometry import shape, mapping\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your Planet API Key is not set as an environment variable, you can paste it below\n",
    "if 'PL_API_KEY' in os.environ:\n",
    "    API_KEY = os.environ['PL_API_KEY']\n",
    "else:\n",
    "    API_KEY = ''\n",
    "    os.environ['PL_API_KEY'] = API_KEY\n",
    "    \n",
    "client = Auth.from_key(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "### Train Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scene_id = '20160831_180231_0e0e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and, if necessary, create train data directory\n",
    "train_dir = os.path.join('data', 'train')\n",
    "pathlib.Path(train_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# define train scene\n",
    "train_scene = os.path.join(train_dir, train_scene_id + '_4B_Analytic.tif')\n",
    "train_scene_metadata = os.path.join(train_dir,\n",
    "                                    train_scene_id + '_4B_Analytic_metadata.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train/20160831_180231_0e0e_4B_Analytic_metadata.xml'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scene_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Planet commandline tool to download the image and metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data/train/20160831_180231_0e0e_3B_AnalyticMS.tif: 100%|████| 178k/178k [01:59<00:00, 1.57MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Analytic Asset\n",
    "async with Session() as sess:\n",
    "    cl = sess.client('data')\n",
    "    # Get Asset\n",
    "    asset_desc = await cl.get_asset(item_type_id='PSScene',item_id=train_scene_id, asset_type_id='ortho_analytic_4b')\n",
    "    # Activate Asset\n",
    "    await cl.activate_asset(asset=asset_desc)\n",
    "    # Wait Asset\n",
    "    await cl.wait_asset(asset=asset_desc)\n",
    "    # Download Asset\n",
    "    asset_path = await cl.download_asset(asset=asset_desc, directory=train_dir, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML Asset\n",
    "async with Session() as sess:\n",
    "    cl = sess.client('data')\n",
    "    # Get Asset\n",
    "    asset_desc = await cl.get_asset(item_type_id='PSScene',item_id=train_scene_id, asset_type_id='ortho_analytic_4b_xml')\n",
    "    # Activate Asset\n",
    "    await cl.activate_asset(asset=asset_desc)\n",
    "    # Wait Asset\n",
    "    await cl.wait_asset(asset=asset_desc)\n",
    "    # Download Asset\n",
    "    asset_path = await cl.download_asset(asset=asset_desc, directory=train_dir, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scene_id = '20160831_180257_0e26'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and, if necessary, create test data directory\n",
    "test_dir = os.path.join('data', 'test')\n",
    "pathlib.Path(test_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# define test scene\n",
    "test_scene = os.path.join(test_dir, test_scene_id + '_4B_Analytic.tif')\n",
    "test_scene_metadata = os.path.join(test_dir,\n",
    "                                   test_scene_id + '_4B_Analytic_metadata.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Planet commandline tool to download the image and metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytic Asset\n",
    "async with Session() as sess:\n",
    "    cl = sess.client('data')\n",
    "    # Get Asset\n",
    "    asset_desc = await cl.get_asset(item_type_id='PSScene',item_id=test_scene_id, asset_type_id='ortho_analytic_4b')\n",
    "    # Activate Asset\n",
    "    await cl.activate_asset(asset=asset_desc)\n",
    "    # Wait Asset\n",
    "    await cl.wait_asset(asset=asset_desc)\n",
    "    # Download Asset\n",
    "    asset_path = await cl.download_asset(asset=asset_desc, directory=test_dir, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML Asset\n",
    "async with Session() as sess:\n",
    "    cl = sess.client('data')\n",
    "    # Get Asset\n",
    "    asset_desc = await cl.get_asset(item_type_id='PSScene',item_id=test_scene_id, asset_type_id='ortho_analytic_4b_xml')\n",
    "    # Activate Asset\n",
    "    await cl.activate_asset(asset=asset_desc)\n",
    "    # Wait Asset\n",
    "    await cl.wait_asset(asset=asset_desc)\n",
    "    # Download Asset\n",
    "    asset_path = await cl.download_asset(asset=asset_desc, directory=test_dir, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AOI and Ground Truth\n",
    "\n",
    "These datasets are created in identify-datasets notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predata_dir = 'pre-data'\n",
    "\n",
    "test_aoi_filename = os.path.join(predata_dir, 'aoi-test.geojson')\n",
    "assert os.path.isfile(test_aoi_filename)\n",
    "\n",
    "train_aoi_filename = os.path.join(predata_dir, 'aoi-train.geojson')\n",
    "assert os.path.isfile(train_aoi_filename)\n",
    "\n",
    "ground_truth_filename = os.path.join(predata_dir, 'ground-truth.geojson')\n",
    "assert os.path.isfile(ground_truth_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Ground Truth Data to AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions: cropping polygons\n",
    "\n",
    "# Uses shapely for geospatial operations\n",
    "def crop_polygons_to_aoi(polygons, aoi):\n",
    "    \"\"\"Crops polygons to the aoi.\n",
    "    \n",
    "    Polygons within aoi are copied. For Polygons that intersect aoi boundary, the \n",
    "    intersection geometry is saved. If the intersection is a MultiPolygon, it is\n",
    "    stored as multiple Polygons.\n",
    "    \n",
    "    :param dict aoi: geojson polygon describing crop feature\n",
    "    :param list features: geojson polygons to be cropped\n",
    "    \"\"\"\n",
    "    aoi_shp = shape(aoi['geometry'])\n",
    "    cropped_features = []\n",
    "    for f in polygons:\n",
    "        shp = shape(f['geometry'])\n",
    "        assert shp.type == 'Polygon'\n",
    "        \n",
    "        if shp.within(aoi_shp):\n",
    "            cropped_features.append(copy.deepcopy(f))\n",
    "        elif shp.intersects(aoi_shp):\n",
    "            # 'cut' features at the aoi boundary by the aoi\n",
    "            cropped_shp = shp.intersection(aoi_shp)\n",
    "            \n",
    "            try:\n",
    "                # try to iterate, which only works for MultiPolygon\n",
    "                for s in cropped_shp:\n",
    "                    new_f = copy.deepcopy(f)\n",
    "                    new_f['geometry'] = mapping(s)\n",
    "                    cropped_features.append(new_f)\n",
    "            except TypeError:\n",
    "                # Polygon is not iterable\n",
    "                new_f = copy.deepcopy(f)\n",
    "                new_f['geometry'] = mapping(cropped_shp)\n",
    "                cropped_features.append(new_f)\n",
    "    return cropped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions: loading and saving geojson\n",
    "\n",
    "def save_geojson(features, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(json.dumps(features))\n",
    "\n",
    "def load_geojson(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_data = load_geojson(ground_truth_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aoi = load_geojson(train_aoi_filename)\n",
    "train_ground_truth_data = crop_polygons_to_aoi(ground_truth_data, train_aoi)\n",
    "print(len(train_ground_truth_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ground_truth_filename = os.path.join(predata_dir, 'ground-truth-train.geojson')\n",
    "save_geojson(train_ground_truth_data,  train_ground_truth_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aoi = load_geojson(test_aoi_filename)\n",
    "test_ground_truth_data = crop_polygons_to_aoi(ground_truth_data, test_aoi)\n",
    "print(len(test_ground_truth_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ground_truth_filename = os.path.join(predata_dir, 'ground-truth-test.geojson')\n",
    "save_geojson(test_ground_truth_data, test_ground_truth_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Train Image to AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions: crop and project an image\n",
    "\n",
    "def _gdalwarp_crop_options(crop_filename):\n",
    "    return ['-cutline', crop_filename, '-crop_to_cutline']\n",
    "    \n",
    "def _gdalwarp_project_options(src_proj, dst_proj):\n",
    "    return ['-s_srs', src_proj, '-t_srs', dst_proj]\n",
    "\n",
    "def _gdalwarp(input_filename, output_filename, options):\n",
    "    commands = ['gdalwarp'] + options + \\\n",
    "               ['-overwrite',\n",
    "                input_filename,\n",
    "                output_filename]\n",
    "    concat_commands = ' '.join(commands)\n",
    "    print(concat_commands)\n",
    "    subprocess.check_call(commands)\n",
    "    print(subprocess.check_call(commands))\n",
    "\n",
    "# lossless compression of an image\n",
    "def _compress(input_filename, output_filename):\n",
    "    commands = ['gdal_translate',\n",
    "                '-co', 'compress=LZW',\n",
    "                '-co', 'predictor=2',\n",
    "                input_filename,\n",
    "                output_filename]\n",
    "    print(' '.join(commands))\n",
    "    subprocess.check_call(commands)\n",
    "    \n",
    "# uses Rasterio to get image srs if dst_srs is specified\n",
    "def warp(input_filename,\n",
    "         output_filename,\n",
    "         crop_filename=None,\n",
    "         dst_srs=None,\n",
    "         overwrite=True,\n",
    "         compress=False):\n",
    "    options = []\n",
    "\n",
    "    if crop_filename is not None:\n",
    "        options += _gdalwarp_crop_options(crop_filename)\n",
    "\n",
    "    if dst_srs is not None:\n",
    "        src_srs = rasterio.open(input_filename).crs['init']\n",
    "        options += _gdalwarp_project_options(src_srs, dst_srs)\n",
    "        \n",
    "    # check to see if output file exists, if it does, do not warp\n",
    "    if os.path.isfile(output_filename) and not overwrite:\n",
    "        print('{} already exists. Aborting warp of {}.'.format(output_filename, input_filename))\n",
    "    elif compress:\n",
    "        with tempfile.NamedTemporaryFile(suffix='.vrt') as vrt_file:\n",
    "            options += ['-of', 'vrt']\n",
    "            _gdalwarp(input_filename, vrt_file.name, options)\n",
    "            _compress(vrt_file.name, output_filename)\n",
    "    else:\n",
    "        _gdalwarp(input_filename, output_filename, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scene_cropped = os.path.join(predata_dir, 'train_scene_cropped.tif')\n",
    "warp(train_scene, train_scene_cropped, crop_filename=train_aoi_filename, overwrite=True, compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy over the image metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_scene_cropped_metadata = os.path.join(predata_dir, 'train_scene_cropped_metadata.xml')\n",
    "shutil.copyfile(train_scene_metadata, train_scene_cropped_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Cropped Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions: loading an image\n",
    "\n",
    "NamedBands = namedtuple('NamedBands', 'b, g, r, nir')\n",
    "\n",
    "def load_masked_bands(filename):\n",
    "    \"\"\"Loads a 4-band BGRNir Planet Image file as a list of masked bands.\n",
    "    \n",
    "    The masked bands share the same mask, so editing one band mask will\n",
    "    edit them all.\"\"\"\n",
    "    with rasterio.open(filename) as src:\n",
    "        b, g, r, nir = src.read()\n",
    "        mask = src.read_masks(1) == 0 # 0 value means the pixel is masked\n",
    "    \n",
    "    bands = NamedBands(b=b, g=g, r=r, nir=nir)\n",
    "    return NamedBands(*[np.ma.array(b, mask=mask)\n",
    "                        for b in bands])\n",
    "\n",
    "print(load_masked_bands(train_scene_cropped).b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions: displaying an image\n",
    "\n",
    "def _linear_scale(ndarray, old_min, old_max, new_min, new_max):\n",
    "    \"\"\"Linear scale from old_min to new_min, old_max to new_max.\n",
    "    \n",
    "    Values below min/max are allowed in input and output.\n",
    "    Min/Max values are two data points that are used in the linear scaling.\n",
    "    \"\"\"\n",
    "    #https://en.wikipedia.org/wiki/Normalization_(image_processing)\n",
    "    return (ndarray - old_min)*(new_max - new_min)/(old_max - old_min) + new_min\n",
    "# print(linear_scale(np.array([1,2,10,100,256,2560, 2660]), 2, 2560, 0, 256))\n",
    "\n",
    "def _mask_to_alpha(bands):\n",
    "    band = np.atleast_3d(bands)[...,0]\n",
    "    alpha = np.zeros_like(band)\n",
    "    alpha[~band.mask] = 1\n",
    "    return alpha\n",
    "\n",
    "def _add_alpha_mask(bands):\n",
    "    return np.dstack([bands, _mask_to_alpha(bands)])\n",
    "\n",
    "def bands_to_display(bands, alpha=True):\n",
    "    \"\"\"Converts a list of bands to a 3-band rgb, normalized array for display.\"\"\"\n",
    "    rgb_bands = np.dstack(bands[:3])\n",
    "\n",
    "    old_min = np.percentile(rgb_bands, 2)\n",
    "    old_max = np.percentile(rgb_bands, 98)\n",
    "    new_min = 0\n",
    "    new_max = 1\n",
    "    scaled = _linear_scale(rgb_bands.astype(np.double),\n",
    "                           old_min, old_max, new_min, new_max)\n",
    "    bands = np.clip(scaled, new_min, new_max)\n",
    "    if alpha is True:\n",
    "        bands = _add_alpha_mask(bands)\n",
    "    return bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "bands = load_masked_bands(train_scene_cropped)\n",
    "plt.imshow(bands_to_display([bands.r, bands.g, bands.b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize'></a>\n",
    "\n",
    "## Visualize Ground Truth Data over Image\n",
    "\n",
    "To ensure accurate alignment between the planet scene and the ground truth data, we will visualize them overlayed in a geographic reference system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Layer for cropped Planet scene\n",
    "\n",
    "First we  project the cropped Planet scene to WGS84 for showing on the map. Then we adjust the scene for display and save as an 8-bit jpeg. Finally, we define the image layer using the projected image bounds.\n",
    "\n",
    "Leaflet appears to support local files if they are jpg ([src](https://gis.stackexchange.com/questions/82936/how-i-can-load-tilelayer-in-leaflet-framework-using-local-tiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions: creating an image layer for display on a map\n",
    "\n",
    "def _save_display_image(src_filename, dst_filename):\n",
    "    # convert to rgb and scale to 8-bit\n",
    "    bands = load_masked_bands(src_filename)\n",
    "    img = bands_to_display([bands.r, bands.g, bands.b])\n",
    "\n",
    "    # save as jpeg\n",
    "    if(os.path.isfile(dst_filename)): os.remove(dst_filename)\n",
    "    matplotlib.image.imsave(dst_filename, img)\n",
    "\n",
    "def create_image_layer(filename):\n",
    "    with tempfile.NamedTemporaryFile(suffix='.tif') as temp_file:\n",
    "        projected_filename = temp_file.name\n",
    "\n",
    "        # project to wgs84\n",
    "        dst_srs = 'epsg:4326' #WGS84\n",
    "        warp(filename, projected_filename, dst_srs=dst_srs)\n",
    "        \n",
    "        # save as jpeg\n",
    "        display_image = os.path.join('data', 'display.jpg')\n",
    "        _save_display_image(projected_filename, display_image)\n",
    "        \n",
    "        # determine image layer bounds\n",
    "        (minx, miny, maxx, maxy) = rasterio.open(projected_filename).bounds\n",
    "        sw = [miny, minx]\n",
    "        ne = [maxy, maxx]\n",
    "\n",
    "        # Create image layer\n",
    "        return ipyl.ImageOverlay(url=display_image, bounds=[sw, ne])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define layer for ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_layer(features):\n",
    "    # Assign colors to classes\n",
    "\n",
    "    # Class descriptions can be found in datasets-identify notebook\n",
    "    agg_classes = ['G', 'R', 'F', 'P', 'T', 'D', 'C', 'V']\n",
    "\n",
    "    # colors determined using [colorbrewer2.org](http://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3)\n",
    "    colors = ['#ffffd9','#edf8b1','#c7e9b4','#7fcdbb','#41b6c4','#1d91c0','#225ea8','#0c2c84']\n",
    "\n",
    "    class_colors = dict((a,c) for a,c in zip(agg_classes, colors))\n",
    "\n",
    "    def get_color(cls):\n",
    "        return class_colors[cls]\n",
    "\n",
    "    feature_collection = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }\n",
    "\n",
    "    for f in feature_collection['features']:\n",
    "        feature_color = get_color(f['properties']['CLASS1'])\n",
    "        f['properties']['style'] = {\n",
    "            'color': feature_color,\n",
    "            'weight': 1,\n",
    "            'fillColor': feature_color,\n",
    "            'fillOpacity': 0.1}\n",
    "\n",
    "    return ipyl.GeoJSON(data=feature_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom = 13\n",
    "center = [38.30933576918588, -121.55410766601564] # lat/lon\n",
    "map_tiles = ipyl.TileLayer(url='http://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}.png')\n",
    "\n",
    "data_map = ipyl.Map(\n",
    "    center=center, \n",
    "    zoom=zoom,\n",
    "    default_tiles = map_tiles\n",
    ")\n",
    "\n",
    "data_map.add_layer(create_image_layer(train_scene_cropped))\n",
    "data_map.add_layer(create_feature_layer(train_ground_truth_data))\n",
    "\n",
    "# display\n",
    "data_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! The data looks nicely registered to the imagery and the crop outlines don't appear to have changed much over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Test Image to AOI\n",
    "\n",
    "Repeat the above procedures for the test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scene_cropped = os.path.join(predata_dir, 'test_scene_cropped.tif')\n",
    "warp(test_scene, test_scene_cropped, crop_filename=test_aoi_filename, overwrite=True, compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scene_cropped_metadata = os.path.join(predata_dir, 'test_scene_cropped_metadata.xml')\n",
    "shutil.copyfile(test_scene_metadata, test_scene_cropped_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize cropped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "bands = load_masked_bands(test_scene_cropped)\n",
    "plt.imshow(bands_to_display([bands.r, bands.g, bands.b]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
