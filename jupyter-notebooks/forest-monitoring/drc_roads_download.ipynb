{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRC Roads - Find and Download Scenes\n",
    "\n",
    "In this notebook we focus on a region in the Democratic Republic of Congo where roads have been built into the forest. In the area of interest (AOI) we are using, the roads were built between September and November 2017.\n",
    "\n",
    "Because the AOI overlaps the OrthoTile grid cells, but only covers a portion of each OrthoTile, this notebook demonstrates working with OrthoTile strips to identify significantly overlapping strips, accessing OrthoTiles as Cloud-Optimized Geotiffs (COGs), and mosaicing multipls COGs on download. Additionally, this notebook demonstrates use of the planet client downloader to manage activation, download, and mosaicing of multiple scenes across multiple strips.\n",
    "\n",
    "This notebook does the following:\n",
    "- use PS Orthotiles\n",
    "- filter by overlap of a set of orthotiles (strips) to an aoi that straddles orthotile grid boundaries\n",
    "- take advantage of the Cloud-Optimized Geotiffs (COGs) Planet provides to download only the pixels within the AOI\n",
    "- mosaic and crop orthotiles on download to a single strip scene that significantly overlaps AOI\n",
    "- use planet client downloader to activate, download, and mosaic multiple scenes across multiple orthotile strips\n",
    "\n",
    "Keywords: Cloud-optimized geotiff, COG, orthotiles, orthotile strips, mosaicing, search, download, downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from planet import Auth, data_filter\n",
    "from planet import Session, DataClient, OrdersClient\n",
    "import rasterio\n",
    "import requests\n",
    "from shapely import geometry as sgeom\n",
    "from shapely.ops import cascaded_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AOI\n",
    "\n",
    "The AOI is a region in the Democratic Republic of Congo that experiences road development between September and November 2017. It is a rectangle that overlaps orthotile grid cell boundaries. Usually, we would redefine the AOI to be within an Orthotile, but we would lose a lot of context if we limited this AOI to only one Orthotile grid cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = {\"geometry\": {\n",
    "    \"type\":\"Polygon\",\n",
    "    \"coordinates\":\n",
    "        [[\n",
    "            [25.42429478260258,1.0255377823058893],\n",
    "            [25.592960813580472,1.0255377823058893],\n",
    "            [25.592960813580472,1.1196578801254304],\n",
    "            [25.42429478260258,1.1196578801254304],\n",
    "            [25.42429478260258,1.0255377823058893]\n",
    "        ]]}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_shape = sgeom.shape(aoi['geometry'])\n",
    "aoi_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Orthotiles that overlap AOI\n",
    "\n",
    "### Build API search request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if your Planet API Key is not set as an environment variable, you can paste it below\n",
    "if os.environ.get('PL_API_KEY', ''):\n",
    "    API_KEY = os.environ.get('PL_API_KEY', '')\n",
    "else:\n",
    "    API_KEY = 'PASTE_YOUR_API_KEY_HERE'\n",
    "\n",
    "client = Auth.from_key(API_KEY)\n",
    "\n",
    "# Setup the session\n",
    "session = requests.Session()\n",
    "\n",
    "# Authenticate\n",
    "session.auth = (API_KEY, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Search Request\n",
    "\n",
    "item_types = [\"PSOrthoTile\"]\n",
    "\n",
    "geom_filter = data_filter.geometry_filter(aoi)\n",
    "date_range_filter = data_filter.date_range_filter(\"acquired\", datetime(month=9, day=1, year=2017), datetime(month=12, day=1, year=2017))\n",
    "cloud_cover_filter = data_filter.range_filter('cloud_cover', None, 5)\n",
    "\n",
    "combined_filter = data_filter.and_filter([geom_filter, date_range_filter, cloud_cover_filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's look at the stats for the request we're trying to make\n",
    "async with Session() as sess:\n",
    "        cl = DataClient(sess)\n",
    "        stats = await cl.get_stats(search_filter=combined_filter, item_types=item_types, interval='month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at our stats\n",
    "print(json.dumps(stats, indent =4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build our search request\n",
    "async with Session() as sess:\n",
    "        cl = DataClient(sess)\n",
    "        request = await cl.create_search(name='drc_roads', search_filter=combined_filter, item_types=item_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can run our search for those items\n",
    "async def search_pl_api(request):\n",
    "    async with Session() as sess:\n",
    "            cl = DataClient(sess)\n",
    "            items = await cl.run_search(request['id'])\n",
    "            item_list = [i async for i in items]\n",
    "    return item_list\n",
    "\n",
    "item_list = await search_pl_api(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save scene data for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_to_scenes(items):\n",
    "    item_types = []\n",
    "\n",
    "    def _get_props(item):\n",
    "        props = item['properties']\n",
    "        \n",
    "        # add data not in properties list\n",
    "        props.update({\n",
    "            'thumbnail': item['_links']['thumbnail'],\n",
    "            'id': item['id'],\n",
    "            'footprint': item['geometry'],\n",
    "        })\n",
    "        return props\n",
    "    \n",
    "    scenes = pd.DataFrame(data=[_get_props(i) for i in items])\n",
    "    \n",
    "    # convert acquired from string to datetime for processing\n",
    "    scenes['acquired'] = pd.to_datetime(scenes['acquired'])\n",
    "    \n",
    "    return scenes\n",
    "\n",
    "scenes = items_to_scenes(item_list)\n",
    "scenes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to scenes with footprints that overlap AOI\n",
    "\n",
    "When the API searches for a scene that overlaps a given AOI, it uses the scene extent. However, we are interested in the scene footprint. That is, we don't care if a portion of a scene with no data overlaps the AOI. We want to filter those scenes out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aoi_intersection(footprint, aoi):\n",
    "    aoi_shape = sgeom.shape(aoi['geometry'])\n",
    "    footprint_shape = sgeom.shape(footprint)\n",
    "    intersection_shape = aoi_shape.intersection(footprint_shape)\n",
    "\n",
    "    try:\n",
    "        intersection_percent = 100 * footprint_shape.area / intersection_shape.area\n",
    "    except ZeroDivisionError:\n",
    "        intersection_percent = 0\n",
    "\n",
    "    data = {'intersection_shape': intersection_shape,\n",
    "            'intersection_fp_perc': intersection_percent}\n",
    "    return pd.Series(data=data)\n",
    "\n",
    "intersections = scenes.footprint.apply(aoi_intersection, args=(aoi,))\n",
    "\n",
    "scenes_inter = pd.concat([scenes, intersections], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out scenes with no intersection\n",
    "scenes_inter = scenes_inter[scenes_inter.intersection_fp_perc > 0]\n",
    "len(scenes_inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip Overlap\n",
    "\n",
    "Because the AOI straddles orthotile grid lines, we focus on the overlap between the AOI and the strip (which is what is cut into orthotiles).\n",
    "\n",
    "We want to filter to strips that have a significant (80%) overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group scenes by strips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_sid = scenes_inter.groupby(['strip_id'])\n",
    "print('{} intersecting strips'.format(scenes_sid.ngroups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(group):\n",
    "    dates = set([a.date() for a in group['acquired']])\n",
    "    assert len(dates) == 1\n",
    "    return min(dates)\n",
    "\n",
    "strip_date = scenes_sid.apply(get_date)\n",
    "strip_date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate strip overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strip_aoi_inter(group, aoi):\n",
    "    '''group: data frame with strip id as index'''\n",
    "    intersections = group['intersection_shape'].tolist()\n",
    "    intersection_shape = cascaded_union(intersections)\n",
    "    aoi_shape = sgeom.shape(aoi['geometry'])\n",
    "\n",
    "    try:\n",
    "        intersection_percent = 100 * intersection_shape.area / aoi_shape.area\n",
    "    except ZeroDivisionError:\n",
    "        intersection_percent = 0 \n",
    "\n",
    "    data = {'strip_intersection_shape': intersection_shape,\n",
    "            'strip_intersection_aoi_perc': intersection_percent}\n",
    "    return pd.Series(data=data)\n",
    "    \n",
    "\n",
    "# with help from: https://stackoverflow.com/a/43616001/2344416\n",
    "strip_aoi_inter = scenes_sid.apply(get_strip_aoi_inter, aoi=aoi)\n",
    "\n",
    "strip_aoi_inter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the distribution of intersection percent of aoi look like?\n",
    "strip_aoi_inter.hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to strips that have significant overlap\n",
    "\n",
    "Here we are defining significant overlap as an overlap of at least 80% of the AOI area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add acquisition date information before filtering\n",
    "strips = strip_aoi_inter.assign(acquisition_date=strip_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to strips that have significant overlap\n",
    "strips_filt = strips[strips.strip_intersection_aoi_perc > 80]\n",
    "print('{} strips with significant overlap'.format(len(strips_filt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the collection dates of strips with significant overlap?\n",
    "strips_filt.acquisition_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 significantly overlapping strips in September, just 1 in October, and 5 in November. Now let's move on to filtering the scene list to scenes in those strips.\n",
    "\n",
    "### Filter to scenes in strips that have significant overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapping_strip_ids = strips_filt.index.tolist()\n",
    "overlapping_strip_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to scenes that are in the resulting strips\n",
    "overlapping_scenes = scenes[scenes['strip_id'].isin(overlapping_strip_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} OrthoTiles in {} strips that significantly overlap the aoi.'.format(\n",
    "    len(overlapping_scenes), len(overlapping_strip_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save overlapping scenes dataframe for use in other notebooks\n",
    "# uncomment to save\n",
    "# overlapping_scenes_filename = os.path.join('pre-data', 'overlapping-scenes')\n",
    "# overlapping_scenes.to_pickle(overlapping_scenes_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create download function\n",
    "\n",
    "Combine all of the steps above into one function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_overlapping_scenes(request, overlap_perc=80):\n",
    "    # get all scenes with overlapping bounds\n",
    "    items = await search_pl_api(request)\n",
    "    scenes = items_to_scenes(items)\n",
    "    print('{} scenes with intersecting borders'.format(len(scenes)))\n",
    "    \n",
    "    # filter to scenes where the footprint overlaps\n",
    "    intersections = scenes.footprint.apply(aoi_intersection, args=(aoi,))\n",
    "    scenes_inter = pd.concat([scenes, intersections], axis=1, sort=False)\n",
    "    scenes_inter = scenes_inter[scenes_inter.intersection_fp_perc > 0]\n",
    "    print('{} scenes with intersecting footprints'.format(len(scenes_inter)))\n",
    "    \n",
    "    # filter to strips with significant overlap\n",
    "    scenes_sid = scenes_inter.groupby(['strip_id'])\n",
    "    strip_aoi_inter = scenes_sid.apply(get_strip_aoi_inter, aoi=aoi)\n",
    "    print('{} intersecting strips'.format(scenes_sid.ngroups))\n",
    "    \n",
    "    strip_date = scenes_sid.apply(get_date)\n",
    "    strips = strip_aoi_inter.assign(acquisition_date=strip_date)\n",
    "    strips_filt = strips[strips.strip_intersection_aoi_perc > overlap_perc]\n",
    "    print('{} strips with significant overlap'.format(len(strips_filt)))\n",
    "    \n",
    "    # filter to scenes that are in resulting strips\n",
    "    overlapping_strip_ids = strips_filt.index.tolist()\n",
    "    overlapping_scenes = scenes[scenes['strip_id'].isin(overlapping_strip_ids)]\n",
    "    \n",
    "    print('There are {} OrthoTiles in {} strips that significantly overlap the aoi'.format(\n",
    "    len(overlapping_scenes), len(overlapping_strip_ids)))\n",
    "    return overlapping_scenes\n",
    "\n",
    "# run again with the same inputs to make sure we get the same results\n",
    "_ = get_overlapping_scenes(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Mosaic Strip Orthotile COGs\n",
    "\n",
    "Because the AOI crosses over Orthotile grid lines, we need multiple orthotiles from one strip to obtain the image that overlaps the AOI. But the portion of each Orthotile that overlaps the AOI is small relative to the orthotile. Therefore, we only want to download the pixels in the orthotile that overlap the AOI. We will accomplish this by accessing the Orthotiles as Cloud-Optimized Geotiffs (COGs).\n",
    "\n",
    "This is a variation of the COG activation and download performed in `temporal-analysis/crop-temporal.ipynb`. For this notebook, we wait until all orthotiles in a strip are activated then we download the COGs together, using `gdalwarp` to perform the download as well as the mosaicing.\n",
    "\n",
    "First, we will go through this exercise with one strip, then we will move onto multiple strips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define asset type\n",
    "\n",
    "For this application, we are interested in the analytic product. This is top-of-atmosphere radiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_type = 'analytic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get scenes that compose a strip\n",
    "\n",
    "Next we need all the ids for scenes that compose a strip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_id = overlapping_strip_ids[0]\n",
    "print(strip_id)\n",
    "\n",
    "strip_scenes = scenes[scenes['strip_id'] == strip_id]\n",
    "strip_scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate Scenes\n",
    "\n",
    "We use the planet api client [downloader](https://planetlabs.github.io/planet-client-python/api/reference.html#planet.api.downloader.Downloader) to handle activation of the scenes. The downloader handles activation, polling activation status, and (if desired), downloading. Because we are using remote COGs, we do not want to download the scene. However, the downloader can still help us out. It has a cool feature where you can provide it with a function to call when a scene is activated.\n",
    "\n",
    "In this section, we will provide it with a function that records the scene id and download url and checks to see if all scenes in the strip are activated. The function is actually just a method of a class (`Tracker`), which maintains a dataset of scene ids and download urls and a list of scene ids in the strip. The method updates the scene id list when it is called by the downloader. Also, it checks to see if all scenes in the strip have been activated. In the future, we will update this part so that when all scenes in a strip are activated, a download and mosaic is triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a downloader that will handle scene activation\n",
    "dl = downloader.create(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This class keeps track of activated scene download urls and the strip scene id's\n",
    "# It also creates the `on_complete` partial function, which can be called\n",
    "# by the downloader to update the list of scene download urls and check to see if all\n",
    "# scenes in the strip are activated\n",
    "class Tracker(object):\n",
    "    def __init__(self, strip_scenes):\n",
    "        self.urls = dict()\n",
    "        self.strip_scenes = set(strip_scenes)\n",
    "        \n",
    "    def get_on_complete(self):\n",
    "        def on_complete(item, asset):\n",
    "            self.urls[item['id']] = asset['location']\n",
    "            print('{}:{}'.format(item['id'], asset['location']))\n",
    "            if self._got_all_strip_scenes():\n",
    "                print('strip complete')\n",
    "        return on_complete\n",
    "    \n",
    "    def _got_all_strip_scenes(self):\n",
    "        return self.strip_scenes.intersection(set(self.urls)) == self.strip_scenes\n",
    "        \n",
    "\n",
    "# create the function that keeps track of the download urls and checks to see if all\n",
    "# scenes in the strip are activated\n",
    "strip_scene_ids = strip_scenes.id.tolist()\n",
    "tracker = Tracker(strip_scene_ids)\n",
    "dl.on_complete = tracker.get_on_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the downloader works with items, so get item object for each scene id\n",
    "strip_scene_items = (client.get_item(item_type, sid).get()\n",
    "                     for sid in strip_scenes.id.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the downloader to activate the scenes and get the download urls\n",
    "dl.shutdown()\n",
    "dl.activate(strip_scene_items, [asset_type])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and mosaic strip scenes\n",
    "\n",
    "Ok! All scenes in the strip are activated. Now it's time to download them. We are using `gdalwarp` to download the scenes, and it turns out `gdalwarp` is also used for mosaicing scenes, so we are going to download and mosaic the scenes all in one step.\n",
    "\n",
    "### Save aoi as geojson file\n",
    "\n",
    "`gdalwarp` requires the aoi used to crop the COG be saved to disk. We want the AOI to persist in git for use elsewhere so we save it in the `pre-data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_save_dir(root_dir='data'):\n",
    "    save_dir = root_dir\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    return save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_geojson_file(aoi_geojson, save_dir):\n",
    "    filename = os.path.join(save_dir, 'aoi.geojson')\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(json.dumps(aoi_geojson))\n",
    "    return filename\n",
    "\n",
    "geojson_filename = save_geojson_file(aoi, create_save_dir('pre-data'))\n",
    "print('wrote AOI to {}'.format(geojson_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define output filename\n",
    "\n",
    "`gdalwarp` saves the mosaic to disk and needs a filename for where to save it.\n",
    "\n",
    "We don't want the mosaic images to persist in git so we save them to the `data` folder, which is not tracked in git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_filename(strip_id, save_dir):\n",
    "    create_save_dir(save_dir)\n",
    "    filename = os.path.join(save_dir, strip_id + '_analytic_mosaic.tif')\n",
    "    return filename\n",
    "\n",
    "output_file = create_output_filename(strip_id, 'data')\n",
    "output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and mosaic COGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(item_ids, download_urls) = zip(*tracker.urls.items())\n",
    "item_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use gdalwarp to only download the aoi portion of the COGs and mosaic them in one step\n",
    "def _gdalwarp(input_filenames, output_filename, options, verbose=False):\n",
    "    commands = ['gdalwarp'] + options + \\\n",
    "               ['-overwrite'] + \\\n",
    "               input_filenames + \\\n",
    "               [output_filename]\n",
    "    if verbose: print(' '.join(commands))\n",
    "    subprocess.check_call(commands)\n",
    "\n",
    "# lossless compression of an image\n",
    "def _compress(input_filename, output_filename, verbose=False):\n",
    "    commands = ['gdal_translate',\n",
    "                '-co', 'compress=LZW',\n",
    "                '-co', 'predictor=2',\n",
    "                input_filename,\n",
    "                output_filename]\n",
    "    if verbose: print(' '.join(commands))\n",
    "    subprocess.check_call(commands)\n",
    "\n",
    "def download_strip_aoi(download_urls, output_filename, geojson_filename, compress=True, verbose=False):\n",
    "    vsicurl_urls = ['/vsicurl/' + d for d in download_urls]\n",
    "    options = [\n",
    "        '-cutline', geojson_filename,\n",
    "        '-crop_to_cutline',\n",
    "    ]\n",
    "    \n",
    "    if compress:\n",
    "        with tempfile.NamedTemporaryFile(suffix='.vrt') as vrt_file:\n",
    "            options += ['-of', 'vrt']\n",
    "            _gdalwarp(vsicurl_urls, vrt_file.name, options, verbose=verbose)\n",
    "            _compress(vrt_file.name, output_filename, verbose=verbose)\n",
    "    else:\n",
    "        _gdalwarp(vsicurl_urls, output_filename, options, verbose=verbose)\n",
    "\n",
    "download_strip_aoi(download_urls, 'data/739199_analytic_mosaic_comp.tif', geojson_filename, verbose=True)\n",
    "download_strip_aoi(download_urls, output_file, geojson_filename, compress=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Strip Mosaic Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local visual module\n",
    "import visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_4band(filename):\n",
    "    with rasterio.open(filename, 'r') as src:\n",
    "        # visual band ordering: red, green, blue, alpha\n",
    "        b, g, r, n = src.read() \n",
    "\n",
    "        # NoData value is 0\n",
    "        mask = b == 0\n",
    "\n",
    "    return [np.ma.array(band, mask=mask) for band in [b, g, r, n]]\n",
    "\n",
    "def visualize_4band(bgrn_bands, title='Orthotile Strip Mosaic', figdim=15):\n",
    "    rgb_bands = [bgrn_bands[i] for i in [2, 1, 0]]\n",
    "    visual.plot_image(rgb_bands, title=title, figsize=(figdim, figdim))\n",
    "\n",
    "print(output_file)\n",
    "visualize_4band(load_4band(output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a beautiful image! It is a little blue due to atmospheric effects. There are a few clouds, but we can clearly see the roads in the forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Mosaic Multiple Strip Orthotile COGs\n",
    "\n",
    "This process is much like the process for downloading and mosaicing a single strip orthotile, but we want to trigger the download as soon as all scenes in a strip are activated. So this will require a bit of a change to the `on_complete()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StripDownloader(object):\n",
    "    def __init__(self, scenes, geojson_file, client, root_dir='data'):\n",
    "        self.scenes = scenes #pandas DataFrame describing scenes to download\n",
    "        self.geojson_file = geojson_file\n",
    "        self.client = client\n",
    "        self.save_dir = root_dir\n",
    "        \n",
    "        self.item_type = 'PSOrthoTile'\n",
    "\n",
    "        self.urls = dict() # this will be populated by on_complete()\n",
    "        self.strip_mosaics = [] # this will be populated by on_complete()\n",
    "        \n",
    "        self.strip_scenes = self._scenes_to_strip_scenes()\n",
    "    \n",
    "    def _scenes_to_strip_scenes(self):\n",
    "        strip_ids = self.scenes.strip_id.unique()\n",
    "        print('{} strips'.format(len(strip_ids)))\n",
    "        \n",
    "        strip_scenes = dict()\n",
    "        for sid in strip_ids:\n",
    "            strip_scenes[sid] = self.scenes[self.scenes['strip_id'] == sid].id.tolist()\n",
    "        return strip_scenes\n",
    "        \n",
    "\n",
    "    def get_on_complete(self, asset_type, verbose=False):\n",
    "        def on_complete(item, asset):\n",
    "            download_url = asset['location']\n",
    "            scene_id = item['id']\n",
    "            if verbose: print('{}'.format(scene_id))\n",
    "\n",
    "            strip_id = item['properties']['strip_id']\n",
    "            if self._completes_strip_scenes(strip_id, scene_id):\n",
    "                # do this after check that this scene_id completes a strip to avoid\n",
    "                # a race condition causing scene to be downloaded multiple times\n",
    "                self.urls[scene_id] = download_url\n",
    "            \n",
    "                output_file = self.get_filename(strip_id, asset_type)\n",
    "                self._download_strip_mosaic(strip_id, output_file, verbose)\n",
    "                self.strip_mosaics.append(output_file)\n",
    "            else:\n",
    "                self.urls[scene_id] = download_url\n",
    "\n",
    "        return on_complete\n",
    "\n",
    "    def _completes_strip_scenes(self, strip_id, scene_id):\n",
    "        activated_scenes_set = set(list(self.urls.keys()) + [scene_id])\n",
    "        strip_scenes_set = set(self.strip_scenes[strip_id])\n",
    "        return strip_scenes_set.intersection(activated_scenes_set) == strip_scenes_set\n",
    "    \n",
    "    def get_filename(self, strip_id, asset_type):\n",
    "        if not os.path.isdir(self.save_dir): os.makedirs(self.save_dir)\n",
    "        \n",
    "        filename = strip_id + '_' + asset_type + '_mosaic.tif'\n",
    "        filepath = os.path.join(self.save_dir, filename)\n",
    "        return filepath\n",
    "  \n",
    "    def _download_strip_mosaic(self, strip_id, output_file, verbose):\n",
    "        scene_ids = self.strip_scenes[strip_id]\n",
    "        download_urls = [self.urls[scene_id]\n",
    "                         for scene_id in scene_ids]\n",
    "\n",
    "        if verbose: print('downloading {} as {}'.format(scene_ids, output_file))\n",
    "        download_strip_aoi(download_urls, output_file, self.geojson_file, verbose=False)\n",
    "    \n",
    "    def run(self, asset_type, overwrite=False, verbose=False):\n",
    "        # filter scenes by those that already exist\n",
    "        if not overwrite:\n",
    "            dl_strip_scenes = self._filter_by_existing_strip_mosaics(self.strip_scenes,\n",
    "                                                                     asset_type,\n",
    "                                                                     verbose)\n",
    "        else:\n",
    "            dl_strip_scenes = self.strip_scenes\n",
    "\n",
    "        if len(dl_strip_scenes):\n",
    "            dl = downloader.create(self.client)\n",
    "            dl.on_complete = self.get_on_complete(asset_type, verbose=verbose)\n",
    "            dl.shutdown()\n",
    "            dl.activate(iter(self._get_items()), [asset_type])\n",
    "        elif verbose:\n",
    "            print('Nothing to download')\n",
    "    \n",
    "    def _filter_by_existing_strip_mosaics(self, strip_scenes, asset_type, verbose):\n",
    "        def _strip_mosaic_exists(strip_id):\n",
    "            strip_mosaic_filename = self.get_filename(strip_id, asset_type)\n",
    "            \n",
    "            found = False\n",
    "            if os.path.isfile(strip_mosaic_filename):\n",
    "                found = True\n",
    "                if verbose: print('found {}'.format(strip_mosaic_filename))\n",
    "            return found\n",
    "        \n",
    "        filtered_strip_ids = (s for s in strip_scenes.keys()\n",
    "                              if not _strip_mosaic_exists(s))\n",
    "        \n",
    "        filt_strip_scenes = {sid: strip_scenes[sid] for sid in filtered_strip_ids}\n",
    "        return filt_strip_scenes\n",
    "        \n",
    "    def _get_items(self):\n",
    "        return [self.client.get_item(self.item_type, sid).get()\n",
    "                for sid in self.scenes.id.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test downloader with initial strip\n",
    "\n",
    "This should be pretty quick as we have already activated all of these scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_strip_downloader = StripDownloader(strip_scenes, geojson_filename, client)\n",
    "single_strip_downloader.run(asset_type, overwrite=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Strip Mosaic and UDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_4band(load_4band(single_strip_downloader.get_filename(strip_id, asset_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udm_asset_type = 'udm'\n",
    "single_strip_downloader.run(udm_asset_type, overwrite=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for loading a UDM image and identifying binary representation as class labels\n",
    "def load_udm(udm_filename):\n",
    "    '''Load single-band bit-encoded UDM as a 2D array.'''\n",
    "    with rasterio.open(udm_filename, 'r') as src:\n",
    "        udm = src.read()[0,...]\n",
    "    return udm\n",
    "\n",
    "def get_udm_labels(udm):\n",
    "    '''Get the binary representation of the UDM values'''\n",
    "    return OrderedDict((v, '{0:08b}'.format(v)) for v in np.unique(udm))\n",
    "\n",
    "udm_filename = single_strip_downloader.get_filename(strip_id, udm_asset_type)\n",
    "udm = load_udm(udm_filename)\n",
    "udm_labels = get_udm_labels(udm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.plot_classified_band(udm, class_labels=udm_labels, title='UDM', figdim=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run downloader on all strips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_downloader = StripDownloader(overlapping_scenes, geojson_filename, client)\n",
    "strip_downloader.run(asset_type, overwrite=False, verbose=True)\n",
    "strip_downloader.run(udm_asset_type, overwrite=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Strip Mosaics and UDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Decimate image band arrays for memory conservation\n",
    "def decimate(arry, num=16):\n",
    "    return arry[::num, ::num].copy()\n",
    "\n",
    "def visualize_image_with_udm(strip_downloader, strip_id):\n",
    "    img_filename = strip_downloader.get_filename(strip_id, asset_type)\n",
    "    img = load_4band(img_filename)\n",
    "    visualize_4band([decimate(b) for b in img], title=strip_id, figdim=5)\n",
    "    \n",
    "    udm_filename = strip_downloader.get_filename(strip_id, udm_asset_type)\n",
    "    udm = decimate(load_udm(udm_filename))\n",
    "    udm_labels = get_udm_labels(udm)\n",
    "    visual.plot_classified_band(udm, class_labels=udm_labels, title=strip_id + ' UDM', figdim=5)\n",
    "\n",
    "for strip_id in overlapping_strip_ids:\n",
    "    visualize_image_with_udm(strip_downloader, strip_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the UDMs associated with the strip mosaics that clouds cover a significant portion of many mosaics, even though we restricted our search to scenes that had less than 5% clouds. To get decent classification, we should filter our strip scenes by the percentage of good UDM pixels in the scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for Scenes Based on Mosaic Scene Usefulness\n",
    "\n",
    "In this section, we create a scene search that filters scenes based on the percentage of useful pixels in the resulting mosaic scene, as determined from the Unusable Data Map (UDM), an asset available alongside the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StripSearcher(object):\n",
    "    def __init__(self, aoi_geojson, begin, end, client, root_dir='data'):\n",
    "        self.aoi = aoi_geojson # aoi geojson\n",
    "        self.begin = begin # datetime indicating begin date\n",
    "        self.end = end # datetime indicating end date\n",
    "        \n",
    "        self.client = client\n",
    "        self.save_dir = root_dir\n",
    "        \n",
    "        self.item_type = 'PSOrthoTile'\n",
    "        \n",
    "        self.overlapping_scenes = None # this is populated by get_overlapping_scenes()\n",
    "        self.good_scenes = None # this is populated by get_good_scenes()\n",
    "    \n",
    "    def search(self, geojson_filename=None, use_udm=True):\n",
    "        self.get_overlapping_scenes()\n",
    "        if use_udm:\n",
    "            if geojson_filename is None:\n",
    "                raise('Must specify geojson_filename')\n",
    "\n",
    "            good_strip_ids = self.get_good_strip_ids(geojson_filename)\n",
    "            all_strip_ids = self.get_strip_ids(self.overlapping_scenes)\n",
    "            print('Filtered to {} strips out of {} strips.'.format(len(good_strip_ids), len(all_strip_ids)))\n",
    "            scenes = self.get_scenes_by_ids(good_strip_ids)\n",
    "        else:\n",
    "            scenes = self.overlapping_scenes\n",
    "        print('{} OrthoTiles found'.format(len(scenes)))\n",
    "        return scenes\n",
    "        \n",
    "    def get_overlapping_scenes(self):\n",
    "        # get all scenes that fit search\n",
    "        items = search_pl_api(self.client,\n",
    "                              build_ps_request(self.aoi, self.item_type, self.begin, self.end))\n",
    "        scenes = items_to_scenes(items)\n",
    "        print('{} OrthoTiles were returned from the api search.'.format(len(scenes)))\n",
    "        \n",
    "        # filter to scenes where footprint overlaps aoi\n",
    "        intersections = scenes.footprint.apply(aoi_intersection, args=(self.aoi,))\n",
    "        scenes_inter = pd.concat([scenes, intersections], axis=1, sort=False)\n",
    "        scenes_inter = scenes_inter[scenes_inter.intersection_fp_perc > 0]\n",
    "        print('There are {} OrthoTiles that overlap aoi.'.format(len(scenes_inter)))\n",
    "        \n",
    "        # filter to scenes in strips that have significant overlap\n",
    "        scenes_sid = scenes_inter.groupby(['strip_id'])\n",
    "        strip_aoi_inter = scenes_sid.apply(get_strip_aoi_inter, aoi=self.aoi)\n",
    "        strips_filt = strip_aoi_inter[strip_aoi_inter.strip_intersection_aoi_perc > 80]\n",
    "        \n",
    "        overlapping_strip_ids = strips_filt.index.tolist()\n",
    "        overlapping_scenes = scenes[scenes['strip_id'].isin(overlapping_strip_ids)]  \n",
    "        print('There are {} OrthoTiles in {} strips that significantly overlap the aoi.'.format(\n",
    "            len(overlapping_scenes), len(overlapping_strip_ids)))\n",
    "        \n",
    "        self.overlapping_scenes = overlapping_scenes\n",
    "    \n",
    "    def get_overlapping_strips(self):\n",
    "        return [s for s in self.overlapping_scenes.strip_id.unique().tolist()]\n",
    "\n",
    "    def get_strip_ids(self, scenes):\n",
    "        return[s for s in scenes.strip_id.unique().tolist()]\n",
    "        \n",
    "    def get_good_strip_ids(self, geojson_filename):\n",
    "        udm_asset_type = 'udm'\n",
    "        strip_downloader = StripDownloader(self.overlapping_scenes, geojson_filename, self.client)\n",
    "        strip_downloader.run(udm_asset_type, overwrite=False, verbose=True)\n",
    "        \n",
    "        strip_ids = self.get_overlapping_strips()\n",
    "        udm_strip_mosaics = [strip_downloader.get_filename(i, udm_asset_type) for i in strip_ids]\n",
    "        \n",
    "        strip_quality = [self._is_good_udm(u) for u in udm_strip_mosaics]\n",
    "        \n",
    "        good_strips = [sid for (sid, squality) in zip(strip_ids, strip_quality) if squality]\n",
    "        return good_strips\n",
    "\n",
    "    def _is_good_udm(self, udm_strip_mosaic):\n",
    "        udm = load_udm(udm_strip_mosaic)\n",
    "        good_percent = ((np.size(udm) - np.count_nonzero(udm)) / np.size(udm)) * 100\n",
    "        return good_percent > 80\n",
    "    \n",
    "    def get_scenes_by_ids(self, strip_ids):\n",
    "        scenes = self.overlapping_scenes.copy()\n",
    "        return scenes[scenes['strip_id'].isin(strip_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin=datetime.datetime(year=2017,month=9,day=1)\n",
    "end=datetime.datetime(year=2017,month=12,day=1)\n",
    "strip_searcher = StripSearcher(aoi, begin, end, client)\n",
    "good_scenes = strip_searcher.search(geojson_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strip_id in strip_searcher.get_strip_ids(good_scenes):\n",
    "    visualize_image_with_udm(strip_downloader, strip_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks much better! From now on, we will filter by udm when downloading strips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
