{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Temporal Analysis\n",
    "\n",
    "Throughout the growth cycle of a crop, the plants sprout, grow, leaf out, and mature. Accordingly, the reflectance measure over the crop, it's spectral signature, changes as well. In this tutorial, we investigate this temporal change in spectral signature of each crop through temporal analysis of satellite imagery of the crops. This type of analysis is made possible with the daily coverage of PlanetScope imagery.\n",
    "\n",
    "We perform analysis in increasing steps of complexity in this tutorial. First, we calculate statics over a single field in a single Surface Reflectance image. We take advantage of the Cloud-Optimized Geotiffs (COGs) Planet provides to download only the pixels within the field, then calculate summary statistics on each band. Next, we calculate statistics over all images covering the field, keeping track of collection date, thus introducing temporal analysis over one field. Finally, we perform temporal analysis over multiple fields, keeping track of their field type classification, to compare temporal signatures across multiple field types. We analyze the results and look into how they can help differentiate the crop types. \n",
    "\n",
    "In this tutorial, we focus on imagery collected within June-September 2017 (the growth season). We use field boundaries and crop type definitions collected in 2015. This dataset is described in the  [Identify Datasets](../crop-classification/datasets-identify.ipynb) notebook and prepared in the [Prepare Datasets](../crop-classification/datasets-prepare.ipynb) notebook. Because the survey data was collected in 2015 and the imagery used in this tutorial was collected in 2017, we expect there to be some inaccuracies in the field type classification, due to rotating crops within the two-year gap.\n",
    "\n",
    "In the interest of calculation time, we limit the calculation of temporal statistics to sample subsets of fields and imagery. Definitions for 946 fields are provided in this dataset. Within the tutorial, we find that approximately 120 images are collected of each field within those dates. We also determine that it takes approximately 3 minutes to activate, download, and calculate statistics from 10 images, 10 minutes for 50 images (due to activation time, this does not scale linearly to 12-18 seconds for a single image). \n",
    "\n",
    "We first perform an initial calculation from 10 scenes per field for 15 fields. It takes approximately 30 minutes to download and process the 150 scenes. In working with this dataset, we create an algorithm for filtering out outliers (likely due to cloudy scenes). The resulting data reveals some differentiation in the statistics from fields, but the data is sparse. Next, we perform another calculation of temporal statistics, this time over 50 images per field and 15 fields, a total of 750 data points and approximately 2.5 hours calculation time. To speed up running this notebook, we cache the statistics data from the both calculations and pull from the cached data unless `run_process` is set to `True`.\n",
    "\n",
    "In analyzing the results, we find that temporal analysis can be helpful in identifying the field types. The mean reflectance across the three field types studied in this notebook (corn, safflower, and sunflower) shows variation between the visual and NIR bands, variation in behavior over time, and variation in steady-state reflectance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "import geojson\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from planet import Auth, reporting\n",
    "from planet import Session, DataClient, OrdersClient\n",
    "import rasterio\n",
    "from shapely.geometry import shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Crop AOI Features\n",
    "\n",
    "We start with `ground-truth.geojson`, which was prepared in the datasets-identify tutorial. This dataset came from a 2015 survey of a region in Sacramento.\n",
    "\n",
    "We then filter to features that correspond with Field Crops. We then sample those features to create our study features. We do so by randomly choosing a sample size of features from each subclass within the class.\n",
    "\n",
    "## Load the Prepared Ground Truth Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file was prepared in the datasets-identify tutorial\n",
    "ground_truth_file = os.path.join('src', 'ground-truth.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_geojson(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "ground_truth = load_geojson(ground_truth_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to Field crops\n",
    "\n",
    "The survey data has attributes that provide the crop type. These attributes are described in a pdf distributed with the shapefile. It was unzipped along with the shapefile files and is located at `data/dwr_survey/09legend.pdf`.\n",
    "\n",
    "We are interested in the Field Crop class. Class is specified by the `CLASS1` property. The Field Crop class is identified by `CLASS1` value of `F`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_ground_truth = [f for f in ground_truth\n",
    "                     if f['properties']['CLASS1'] == 'F']\n",
    "print('{} out of {} features are field crops.'\n",
    "      .format(len(crop_ground_truth),len(ground_truth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to Valid Subclasses\n",
    "\n",
    "The field subclasses are:\n",
    "- 1: Cotton\n",
    "- 2: Safflower\n",
    "- 3: Flax\n",
    "- 4: Hops\n",
    "- 5: Sugar Beets\n",
    "- 6: Corn (field & sweet)\n",
    "- 7: Grain sorghum\n",
    "- 8: Sudan\n",
    "- 9: Castor beans\n",
    "- 10: Beans (dry)\n",
    "- 11: Miscellaneous field\n",
    "- 12: Sunflowers\n",
    "- 13: Hybrid sorghum/sudan\n",
    "- 14: Millet\n",
    "- 15: Sugar cane\n",
    "\n",
    "In this section, we filter out features that are uncategorized (subclass is `**`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_type_names = {\n",
    "    1: 'cotton',\n",
    "    2: 'safflower',\n",
    "    3: 'flax',\n",
    "    4: 'hops',\n",
    "    5: 'sugar beets',\n",
    "    6: 'corn',\n",
    "    7: 'grain sorghum',\n",
    "    8: 'sudan',\n",
    "    9: 'castor beans',\n",
    "    10: 'beans',\n",
    "    11: 'misc field',\n",
    "    12: 'sunflowers',\n",
    "    13: 'hybrid sorghum/sudan',\n",
    "    14: 'millet',\n",
    "    15: 'sugar cane'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_crop_ground_truth = [f for f in crop_ground_truth\n",
    "                         if f['properties']['SUBCLASS1'] != '**']\n",
    "print('{} out of {} crop field features are categorized.'\n",
    "      .format(len(cat_crop_ground_truth),len(crop_ground_truth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Stats for a Single Field\n",
    "\n",
    "We will run through the process of calculating stats for a single field.\n",
    "\n",
    "This involves finding the overlapping scenes, activating them, and then calculating stats on the pixels within the field directly from the COG at the download url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and create test directory\n",
    "# delete it if it already exists to ensure we start from a clear slate\n",
    "test_dir = Path('data', 'test')\n",
    "if os.path.isdir(test_dir):\n",
    "    shutil.rmtree(test_dir)\n",
    "test_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_geojson = cat_crop_ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape(field_geojson['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(field_geojson):\n",
    "    return field_geojson['id']\n",
    "\n",
    "print(get_id(field_geojson))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save geojson file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_save_dir(aoi_geojson, root_dir='data'):\n",
    "    save_dir = os.path.join(root_dir, get_id(aoi_geojson))\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    return save_dir\n",
    "\n",
    "save_dir = create_save_dir(field_geojson)\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_geojson_file(aoi_geojson, save_dir):\n",
    "    filename = os.path.join(save_dir, 'aoi.geojson')\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(json.dumps(aoi_geojson))\n",
    "    return filename\n",
    "\n",
    "geojson_filename = save_geojson_file(field_geojson, save_dir)\n",
    "print('wrote to {}'.format(geojson_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_aoi = field_geojson['geometry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for Overlapping Scenes\n",
    "\n",
    "In this section we search for surface reflectance 4band PS scenes that were collected between June and October, 2017 that also overlap the field aoi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command-line search\n",
    "# !planet data search --item-type PSScene --geom $geojson_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your Planet API Key is not set as an environment variable, you can paste it below\n",
    "API_KEY = os.environ.get('PL_API_KEY', 'PASTE_API_KEY_HERE')\n",
    "\n",
    "# Setup Planet Data API base URL\n",
    "URL = \"https://api.planet.com/data/v1\"\n",
    "\n",
    "# Setup the session\n",
    "session = requests.Session()\n",
    "\n",
    "# Authenticate\n",
    "session.auth = (API_KEY, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an API Request from the search specifications\n",
    "\n",
    "item_type = ['PSScene']\n",
    "\n",
    "geom_filter = {\n",
    "   \"type\":\"GeometryFilter\",\n",
    "   \"field_name\":\"geometry\",\n",
    "   \"config\":field_aoi\n",
    "}\n",
    "\n",
    "date_range_filter = {\n",
    "\"type\":\"DateRangeFilter\",\n",
    "\"field_name\":\"acquired\",\n",
    "\"config\":{\n",
    "  \"gt\":\"2017-06-01T00:00:00Z\", \n",
    "   \"lt\": \"2017-10-01T00:00:00Z\"}\n",
    "}\n",
    "\n",
    "combined_filter = {\n",
    "\"type\":\"AndFilter\",\n",
    "\"config\":[\n",
    "    geom_filter,\n",
    "    date_range_filter]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Request\n",
    "# Also Get Some Stats About Our Request!\n",
    "\n",
    "async with Session() as sess:\n",
    "    cl = DataClient(sess)\n",
    "    request = await cl.create_search(name='field_search',search_filter=combined_filter, item_types=item_type)\n",
    "    stats = await cl.get_stats(search_filter=combined_filter, item_types=item_type, interval='month')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the stats\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities for retrieving scene information and filtering to only scenes that totally overlap field\n",
    "def get_items(client, request, limit=500):\n",
    "    # run search\n",
    "    # if you don't have an API key configured, this will raise an exception\n",
    "    result = client.quick_search(request)\n",
    "    return result.items_iter(limit=limit)\n",
    "\n",
    "def filter_by_overlaps(items, aoi):\n",
    "    aoi_shape = shape(aoi)\n",
    "    \n",
    "    def get_overlap(item):\n",
    "        item_shape = shape(item['geometry'])\n",
    "        overlap = 100.0*(aoi_shape.intersection(item_shape).area / aoi_shape.area)\n",
    "        return overlap\n",
    "    return (i for i in items if get_overlap(i) > 99)\n",
    "\n",
    "\n",
    "async with Session() as sess:\n",
    "    cl = DataClient(sess)\n",
    "    items = await cl.run_search(search_id=request['id'])\n",
    "    item_list = [i async for i in items]\n",
    "    filtered_items = filter_by_overlaps(item_list, field_aoi)\n",
    "    filtered_list = [i for i in filtered_items]  \n",
    "\n",
    "\n",
    "print(filtered_list[0]['id'])\n",
    "print(filtered_list[0]['properties'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see all of the image IDs matching our search request\n",
    "for i in filtered_list:\n",
    "    print (i['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate Scene\n",
    "\n",
    "We use the planet api client [downloader](https://planetlabs.github.io/planet-client-python/api/reference.html#planet.api.downloader.Downloader) to handle activation of the scenes. The downloader handles activation, polling activation status, and (if desired), downloading. Because we are using remote COGs, we do not want to download the scene. However, the downloader can still help us out. It has a cool feature where you can provide it with a function to call when a scene is activated.\n",
    "\n",
    "In this section, we will provide it with a function that records the scene id and download url. The function is actually just a method of a class (`Tracker`) that maintains a dataset of ids and download urls. The method simply updates that list when it is called by the downloader.\n",
    "\n",
    "The use of this `Tracker` class to keep track of the download urls is a bit of a complicated solution for what we need. Similarly, the use of the bulk downloader to activate only one scene is overly complicated. However, this is serving as a simple example of the workflow. We will use something very similar to this process to activate multiple scenes and calculate the stats of only the pixels within the field aoi in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's label the first item in our filtered list\n",
    "item = filtered_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can look at the item's \"permissions\" to see what assets we have available\n",
    "# We are interested in the \"ortho_analytic_4b_sr\" asset\n",
    "item['_permissions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the assets link for the item\n",
    "assets_url = item[\"_links\"][\"assets\"]\n",
    "\n",
    "# Send a GET request to the assets url for the item (Get the list of available assets for the item)\n",
    "res = session.get(assets_url)\n",
    "\n",
    "# Assign a variable to the response\n",
    "assets = res.json()\n",
    "\n",
    "# Assign a variable to the visual asset from the item's assets\n",
    "orthoanalyticsr_asset = assets[\"ortho_analytic_4b_sr\"]\n",
    "\n",
    "# Print the visual asset data\n",
    "print(orthoanalyticsr_asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the activation url for a particular asset (in this case the basic_analytic_4b asset)\n",
    "activation_url = orthoanalyticsr_asset[\"_links\"][\"activate\"]\n",
    "\n",
    "# Send a request to the activation url to activate the item\n",
    "res = session.get(activation_url)\n",
    "\n",
    "# Print the response from the activation request\n",
    "print(res.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A response of 202 means that the request has been accepted and the activation will begin shortly. A 204 code indicates that the asset is already active and no further action is needed. A 401 code means the user does not have permissions to download this file.\n",
    "\n",
    "Below, we are polling the API until the item is done activation. This may take awhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_activated = False\n",
    "\n",
    "while asset_activated == False:\n",
    "    asset_status = orthoanalyticsr_asset[\"status\"]\n",
    "    print(asset_status)\n",
    "    \n",
    "    # If asset is already active, we are done\n",
    "    if asset_status == 'active':\n",
    "        asset_activated = True\n",
    "        print(\"Asset is active and ready to download\")\n",
    "\n",
    "# Print the ps3b_analytic asset data    \n",
    "print(orthoanalyticsr_asset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GDAL to Download AOI Image\n",
    "\n",
    "Now that we know the download url and have the crop aoi, we can use the COG nature of Planet scenes to only download the AOI Image. This saves us a great deal of download time and local storage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orthoanalyticsr_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_id = item['id']\n",
    "download_url = orthoanalyticsr_asset['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to use the vsicurl gdal driver to work with COGs.\n",
    "vsicurl_url = '/vsicurl/' + download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_filename(item_id, save_dir):\n",
    "    filename = os.path.join(save_dir, item_id + '.tif')\n",
    "    return filename\n",
    "\n",
    "output_file = create_output_filename(item_id, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use gdalwarp and the crop_to_cutline argument to only download the aoi portion of the COG\n",
    "def _gdalwarp(input_filename, output_filename, options, verbose=False):\n",
    "    commands = ['gdalwarp'] + options + \\\n",
    "               ['-overwrite',\n",
    "                input_filename,\n",
    "                output_filename]\n",
    "    if verbose: print(' '.join(commands))\n",
    "    subprocess.check_call(commands)\n",
    "    \n",
    "def download_scene_aoi(download_url, output_filename, geojson_filename, verbose=False):\n",
    "    vsicurl_url = '/vsicurl/' + download_url\n",
    "    options = [\n",
    "        '-cutline', geojson_filename,\n",
    "        '-crop_to_cutline',\n",
    "    ]\n",
    "    _gdalwarp(vsicurl_url, output_filename, options, verbose=verbose)\n",
    "\n",
    "%time download_scene_aoi(download_url, output_file, geojson_filename, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local visual module\n",
    "# autoreload because visual is in development\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sr(filename):\n",
    "    with rasterio.open(filename, 'r') as src:\n",
    "        # visual band ordering: red, green, blue, alpha\n",
    "        b, g, r, n = src.read() \n",
    "\n",
    "        # NoData value is 0\n",
    "        mask = b == 0\n",
    "\n",
    "    return [np.ma.array(band, mask=mask) for band in [b, g, r, n]]\n",
    "\n",
    "def visualize_sr(filename, title='Cropped Scene'):\n",
    "    bgrn_bands = load_sr(filename)\n",
    "\n",
    "    rgb_bands = [bgrn_bands[i] for i in [2, 1, 0]]\n",
    "    visual.plot_image(rgb_bands, title=title, figsize=(5, 5))\n",
    "\n",
    "print(output_file)\n",
    "visualize_sr(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Band Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_band_stats(band):\n",
    "    \"\"\"Calculate simple statistics for a band\"\"\"\n",
    "    # Consider adding stats from here:\n",
    "    # https://docs.scipy.org/doc/scipy/reference/stats.mstats.html\n",
    "    stats = {\n",
    "        'mean': band.mean(),\n",
    "        'std': band.std(),\n",
    "        'max': band.max(),\n",
    "        'min': band.min(),\n",
    "        'count': band.count()\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "def get_stats(filename):\n",
    "    bands = load_sr(filename)\n",
    "    stats = [get_band_stats(band)\n",
    "             for band in bands]\n",
    "    return stats\n",
    "\n",
    "print(get_stats(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.aoi_geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Stats Directly For Multiple Scenes\n",
    "\n",
    "In this section, we download the aoi image and calculate the band statistics all together in a function that is called directly by the downloader.\n",
    "\n",
    "In the interest of time, we limit the number of images to 10 or less (though the search may return 10 scenes, some of them may not completely overlap the field)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Orders Request\n",
    "# We're requesting 10 Scene IDs for this example\n",
    "\n",
    "request = {  \n",
    "   \"name\":\"multiple scenes order\",\n",
    "   \"products\":[\n",
    "      {  \n",
    "         \"item_ids\":[  \n",
    "            \"20170729_181143_0e2f\",\n",
    "            \"20170926_190204_0f2e\",\n",
    "            \"20170924_180919_100c\",\n",
    "            \"20170923_180901_0f31\",\n",
    "            \"20170923_181342_0e0f\",\n",
    "            \"20170922_181038_1004\",\n",
    "            \"20170920_180941_102a\",\n",
    "            \"20170919_181118_1008\",\n",
    "            \"20170919_181016_1032\",\n",
    "            \"20170909_180818_101b\"\n",
    "         ],\n",
    "         \"item_type\":\"PSScene\",\n",
    "         \"product_bundle\":\"analytic_sr_udm2\"\n",
    "      }\n",
    "   ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "async with Session() as sess:\n",
    "    cl = OrdersClient(sess)\n",
    "    with reporting.StateBar(state='creating') as bar:\n",
    "        order_request = await cl.create_order(request)\n",
    "        # We need to wait for our Order to be ready for download\n",
    "        # This may take several minutes\n",
    "        bar.update(state='created', order_id=order_request['id'])\n",
    "        await cl.wait(order_request['id'], callback=bar.update_state)\n",
    "    download_order = await cl.download_order(order_request['id'], progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subclass(crop_geojson):\n",
    "    return crop_geojson['properties']['SUBCLASS1']\n",
    "\n",
    "def get_date(scene_id):\n",
    "    date_str = scene_id[:8]\n",
    "    return datetime.datetime.strptime(date_str, \"%Y%m%d\").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsCalculator(object):\n",
    "    def __init__(self, aoi_geojson, root_dir='data'):\n",
    "        self.save_dir = create_save_dir(aoi_geojson, root_dir=root_dir)\n",
    "        self.geojson_file = save_geojson_file(aoi_geojson, self.save_dir)\n",
    "        self.aoi_geojson = aoi_geojson\n",
    "        self.info = []\n",
    "        \n",
    "    def get_on_complete(output_file, overwrite=False, verbose=False):\n",
    "        band_names = ['blue', 'green', 'red', 'nir']\n",
    "        band_stats = get_stats(output_file)\n",
    "        for stats, name in zip(band_stats, band_names):\n",
    "            info = {\n",
    "                'field_id': get_id(output_file.aoi_geojson),\n",
    "                'field_type': get_subclass(output_file.aoi_geojson),\n",
    "                'scene_id': scene_id,\n",
    "                'scene_filename': output_file,\n",
    "                'band': name,\n",
    "                'date': get_date(scene_id)\n",
    "            }\n",
    "            info.update(stats)\n",
    "            self.info.append(info)\n",
    "\n",
    "        return on_complete\n",
    "\n",
    "async def get_field_stats_info(pathlist):\n",
    "    if max_scenes > 0:\n",
    "        stats_calculator = StatsCalculator(field_geojson)\n",
    "        \n",
    "        for path in pathlist:\n",
    "            if Path(path).name.endswith('_SR.tif'):\n",
    "                stats_calculator.get_on_complete(path)\n",
    "                info = stats_calculator.info\n",
    "    else:\n",
    "        # skip activation if max_scenes is not > 0\n",
    "        info = []\n",
    "    return pd.DataFrame(data=info)\n",
    "\n",
    "# it takes about 3-4 minutes to download and calculate stats on 10 scenes\n",
    "max_scenes=10\n",
    " \n",
    "# we set overwrite to False (the default value of that variable) so we do not re-download\n",
    "# the image if it is already cached\n",
    "field_info = await get_field_stats_info(download_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('calculated statistics across {} scenes'.format(int(len(field_info) / 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show first few scenes of field\n",
    "\n",
    "# we filter to just red data points because there are 4 data points for each scene\n",
    "# (red, green, blue, and NIR)\n",
    "collects = field_info[field_info.band == 'red'][:3]\n",
    "\n",
    "for collect in collects.itertuples():\n",
    "    title='{}\\n'.format(collect.scene_id)\n",
    "    title += 'mean % : {}'.format(collect.mean)\n",
    "    visualize_sr(collect.scene_filename, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Band Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_band_statistic(df, stat, title):\n",
    "    for field_type, group in df.groupby(['field_type']):\n",
    "        field_name = field_type_names[int(field_type)]\n",
    "\n",
    "        x = group['date'].tolist()\n",
    "        y = group[stat].tolist()\n",
    "        plt.scatter(x, y, marker='^', label=field_name)\n",
    "    \n",
    "    all_x = df['date'].tolist()\n",
    "    one_day = datetime.timedelta(days=1)\n",
    "    plt.xlim(min(all_x) - one_day, max(all_x) + one_day)\n",
    "    plt.margins(x=0)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(title)  \n",
    "\n",
    "def plot_statistic(df, statistic, title=None):\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "    bands = ['blue', 'green', 'red', 'nir']\n",
    "    \n",
    "    title = title if title is not None else statistic\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    for i, band in enumerate(bands):\n",
    "        ax = fig.add_subplot(1,4,i+1)\n",
    "        band_group = df[df['band'] == band]\n",
    "        plot_band_statistic(band_group, statistic, band)\n",
    "\n",
    "    ax.legend(bbox_to_anchor=(1.05, 0), loc='lower left', borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_statistics(df):\n",
    "    plot_statistic(df, 'mean')\n",
    "    plot_statistic(df, 'std')\n",
    "\n",
    "plot_all_statistics(field_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Stats for Multiple Fields\n",
    "\n",
    "Up to this point, we have focused on stats of a single field. Now we get into the meat of things, calculating stats across multiple fields and grouping by crop type (specified by the subclass property).\n",
    "\n",
    "## Determine List of Sample Features\n",
    "\n",
    "There are just too many categorized crop fields to calculate statistics on them all in a reasonable time using just one CPU. Therefore, we will create a list of sample features, features that equally represent the crop types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the subclasses in this set and counts\n",
    "subclasses_list = [field_geojson['properties']['SUBCLASS1']\n",
    "                   for field_geojson in cat_crop_ground_truth]\n",
    "subclasses = dict([x, subclasses_list.count(x)]\n",
    "                  for x in set(subclasses_list))\n",
    "print('subclasses and counts')\n",
    "print(json.dumps(subclasses, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples for each subclass\n",
    "num_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the subclasses to those with adequate number of features\n",
    "filt_subclasses = [subclass\n",
    "                   for (subclass, count) in subclasses.items()\n",
    "                   if count > num_samples]\n",
    "print('filtered subclasses: {}'.format(filt_subclasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets focus on only 3 subclasses for now, comment to use all subclasses\n",
    "filt_subclasses = filt_subclasses[:3]\n",
    "print('filtered subclasses: {}'.format(filt_subclasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of sample features\n",
    "# first filter to features within a subclass, then randomly pick a sample of those features\n",
    "\n",
    "np.random.seed(0) # make random sampling repeatable\n",
    "\n",
    "sample_features = []\n",
    "for subclass in filt_subclasses:\n",
    "    subclass_features = [f for f in crop_ground_truth if get_subclass(f) == subclass]\n",
    "    sample_features.extend(np.random.choice(subclass_features, num_samples, replace=False))\n",
    "print('{} sample field features'.format(len(sample_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Stats for Sample Features\n",
    "\n",
    "In this section, we calculate statistics for all of the sample features. We loop through each of the fields, activating and calculating stats for each scene that overlaps the field.\n",
    "\n",
    "The calculation of stats for one field from 50 scenes takes 10 minutes. Therefore, we expect the calculation of stats for 15 fields from 50 scenes each to take 150 minutes, or 2.5 hours. That's quite a while! For now, we will limit the number of scenes to 10, which should take 30 minutes to process. Still a while, but not unreasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_scenes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_field_stats_info(sample_features, client, item_type, max_scenes=10):\n",
    "    all_info = []\n",
    "\n",
    "    for field_geojson in sample_features:\n",
    "        info = get_field_stats_info(field_geojson, max_scenes, client, item_type)\n",
    "        all_info.extend(info)\n",
    "    \n",
    "    return all_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_process = False\n",
    "scenes_info_filename = 'src/scene_info_df.pkl'\n",
    "\n",
    "if run_process:\n",
    "    info_df = analyze_more_scenes(sample_features, client, item_type)\n",
    "    \n",
    "    # uncommenting overwrites cached data\n",
    "    # info_df.to_pickle(scenes_info_filename)\n",
    "else:\n",
    "    info_df = pd.read_pickle(scenes_info_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Stats\n",
    "\n",
    "We explore the statistics results by plotting them and then filtering outliers. We look for entries where the mean statistic of all 4 bands are all outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_statistics(info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to see the results due to the outliers across all of the bands. These outliers could potentially be cloudy scenes. To clean up the results, we will filter out the scenes that have mean values that are outliers across all bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bad_scenes(df):\n",
    "    bad_scene_sets = []\n",
    "    for band, group in df.groupby(['band']):\n",
    "        m = group['mean']\n",
    "        mmax = m.mean() + 2 * m.std()\n",
    "        outliers = group[m > mmax]\n",
    "        bad_scene_sets.append(set(outliers['scene_id']))\n",
    "    \n",
    "    # get list of scenes that have outliers in all 4 bands\n",
    "    bad_scenes = set.intersection(*bad_scene_sets)\n",
    "    print('{} bad scenes:\\n{}'.format(len(bad_scenes), bad_scenes))\n",
    "    bad_scene_entry = df.scene_id.isin(bad_scenes)\n",
    "\n",
    "    print('{} entries from the bad scenes filtered out'.format(bad_scene_entry.sum()))\n",
    "\n",
    "    return df[~bad_scene_entry]\n",
    "\n",
    "filtered_info_df = filter_bad_scenes(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_statistics(filtered_info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! The filter removed the outliers. From these results, it looks like corn mean reflectance is darker in the blue, green, and red bands than sunflowers and safflower. Also, the mean reflectance of corn in the NIR band decreases over time. Sunflowers and safflower are more difficult to distinguish. Ultimately, more data points would help here. \n",
    "\n",
    "The section below will run calculations on 50 scenes per field. It can take 2.5 hours so is not for the faint of heart! The data is also cached, so you can load and explore it without having to go through all of that processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_more_scenes(sample_features, client, item_type):\n",
    "    dl.shutdown()\n",
    "    all_info = get_all_field_stats_info(sample_features, client, item_type, max_scenes=50)\n",
    "    info_df = pd.DataFrame(data=all_info)\n",
    "    filtered_info_df = filter_bad_scenes(info_df)\n",
    "    \n",
    "    return filtered_info_df\n",
    "\n",
    "run_process = False\n",
    "more_scenes_filename = 'src/more_scenes_df.pkl'\n",
    "\n",
    "if run_process:\n",
    "    more_scenes_df = analyze_more_scenes(sample_features, client, item_type)\n",
    "    \n",
    "    # uncommenting overwrites cached data\n",
    "    # filtered_info_df.to_pickle(more_scenes_filename)\n",
    "else:\n",
    "    more_scenes_df = pd.read_pickle(more_scenes_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_statistics(more_scenes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots give a little more insight into the field temporal statistics. Sunflower and corn NIR reflectance means decrease over time, while safflower NIR reflectance mean stays pretty steady. Corn red, green, and blue reflectance mean stays pretty steady, with a slight increase over time. Sunflower red, green, and blue reflectance mean is all over the board, which is kind of confusing. Safflower red, green, and blue reflectance mean is, similar to corn, pretty steady with a slow increase over time.\n",
    "\n",
    "In general, there isn't much of a pattern in the standard deviation of the reflectance bands. Corn does stand out as having the lowest reflectance standard deviation across the blue, green, and red bands. Additionally, NIR reflectance standard deviation is higher. The NIR reflectance is much higher in the NIR band than the red, green and blue bands (which makes sense, we are looking at actively growing fields), and the higher standard deviation could either be due to increased sensitivity to the health of the crops vs the visual bands, or it could be due to higher noise associated with the higher signal of the NIR reflectance band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
